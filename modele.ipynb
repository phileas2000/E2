{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading https://files.pythonhosted.org/packages/98/95/c8606f640e2e932cf6bdcc7626ef502d528fbfbb1024a3bb214366e6c484/scikeras-0.8.0-py3-none-any.whl\n",
      "Requirement already satisfied: packaging<22.0,>=0.21 in c:\\users\\philg\\appdata\\roaming\\python\\python37\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=3; python_version < \"3.8\" in d:\\programmes2\\anaconda\\lib\\site-packages (from scikeras) (4.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\programmes2\\anaconda\\lib\\site-packages (from scikeras) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programmes2\\anaconda\\lib\\site-packages (from packaging<22.0,>=0.21->scikeras) (2.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in d:\\programmes2\\anaconda\\lib\\site-packages (from importlib-metadata>=3; python_version < \"3.8\"->scikeras) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\programmes2\\anaconda\\lib\\site-packages (from importlib-metadata>=3; python_version < \"3.8\"->scikeras) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\philg\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\philg\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\philg\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programmes2\\anaconda\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: more-itertools in d:\\programmes2\\anaconda\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=3; python_version < \"3.8\"->scikeras) (7.2.0)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.8.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56       0.78947368 0.66666667 1.         0.80769231]\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_shape=(8,), activation='relu',kernel_regularizer='l1_l2'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# load the dataset\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "scaler=StandardScaler()\n",
    "#X=scaler.fit_transform(X)\n",
    "Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2,random_state=150)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile the keras model\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=30)\n",
    "model_cl = KerasClassifier(model=create_model, epochs=150,validation_split=0.15, batch_size=10, verbose=0,callbacks=es)\n",
    "#model.fit(X,y,epochs=15,batch_size=10)\n",
    "#model_cl=KerasClassifier(model)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=150)\n",
    "score=cross_val_score(model_cl, X, y, cv=kfold,scoring='precision')\n",
    "print(score)\n",
    "\n",
    "n_splits=5\n",
    "\"\"\"kf = KFold(n_splits=n_splits,random_state=150,shuffle=True)\n",
    "\n",
    "\n",
    "erreurs_moy=0\n",
    "for train_index, test_index in kf.split(Xtrain):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train,validation_split=0.25, epochs=150, batch_size=10, verbose=0,callbacks=es)\n",
    "    predictions = (model.predict(X_test) > 0.5).astype(int)\n",
    "    # summarize the first 5 cases\n",
    "    erreurs=0\n",
    "    nb_test=len(X[test_index])\n",
    "    for i in range(nb_test):\n",
    "        if predictions[i] != y_test[i]:\n",
    "            erreurs+=1 \n",
    "    erreurs_moy+=erreurs\n",
    "    print(str(erreurs/nb_test*100)+\"% d'erreurs\")\n",
    "print(str(erreurs_moy/nb_test/n_splits*100)+\"% d'erreur moyenne\")\n",
    "\"\"\"\n",
    "a=''\n",
    "# define the keras model\n",
    "\n",
    "# make class predictions with the model\n",
    "\n",
    "# summarize the first 5 cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'erreurs_moy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0c217f850c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0merreurs\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0merreurs_moy\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0merreurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merreurs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnb_test\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"% d'erreurs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'erreurs_moy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(Xtrain, ytrain,validation_split=0.25, epochs=150, batch_size=10, verbose=0,callbacks=es)\n",
    "\n",
    "\n",
    "predictions = (model.predict(Xtest) > 0.5).astype(int)\n",
    "erreurs=0\n",
    "nb_test=len(Xtest)\n",
    "for i in range(nb_test):\n",
    "    if predictions[i] != ytest[i]:\n",
    "        erreurs+=1 \n",
    "    erreurs_moy+=erreurs\n",
    "print(str(erreurs/nb_test*100)+\"% d'erreurs\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = (model.predict(Xtrain) > 0.5).astype(int)\n",
    "erreurs=0\n",
    "nb_test=len(Xtest)\n",
    "for i in range(nb_test):\n",
    "    #print(predictions[i])\n",
    "    #print(ytrain[i])\n",
    "    if predictions[i] != ytrain[i]:\n",
    "        erreurs+=1 \n",
    "    erreurs_moy+=erreurs\n",
    "print(str(erreurs/nb_test*100)+\"% d'erreurs\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Par défaut: 60% précision\n",
    "Avec 6 couches: trop de couches 62%\n",
    "Scaling, ajout deux couches,dropout,EarlyStopping,150 epochs max: 68%\n",
    "L1_L2 régularisateur: 66%\n",
    "Retiré scaling:76% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SANS TRAIN-TEST SPLIT!\n",
    "#origine: 33% d'erreur  31 %\n",
    "#rajout 3 couches denses: 26% d'erreur    29 % \n",
    "#standardScaling données: 16% d'erreur    22%\n",
    "#triplé temps d'entrainement: 10% d'erreur   25%\n",
    "\n",
    "#défaut: 27%\n",
    "#standardisation:  23%\n",
    "#ajotué deux couches : 21%\n",
    "#earlyStopping: 23,5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Défaut:  29,32,31.5 = 31\n",
    "StandardScaler: 22.3  ,24.7 23.5 = 23.5\n",
    "Trois couches    23 23.7  23 =23\n",
    "150 period:  22 23.6 23    = 23\n",
    "EarlyStopping: 23 24.5  20  = 23\n",
    "Dropout: 21,23,22 = 22\n",
    " \n",
    "15.84,20,22,18%\n",
    "\n",
    "\n",
    "-standardisation:\n",
    "-layers:\n",
    "-dropout:65%\n",
    "full:65%\n",
    "\n",
    "0.6   par défaut\n",
    "0.625 trop de couches\n",
    "0.68 meilleur\n",
    "0.66 L1_L2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
